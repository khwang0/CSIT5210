{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# CSIT5210 Assignment\n",
    "\n",
    "## Spring 2019\n",
    "\n",
    "### Instructor: Dr. Kenneth Leung (kwtleung@cse.ust.hk)\n",
    "\n",
    "### TA: Dr. Kevin Wang (kevinw@ust.hk)\n",
    "\n",
    "\n",
    "---\n",
    "\n",
    "## [New Data Avaliable]("https://home.cse.ust.hk/~kevinw/CSIT5210/data_set1.zip")\n",
    "## [Group Signup link](https://docs.google.com/spreadsheets/d/1k523REcIAs6uo5rT0nISXjgk8R58ARvzjWE48pKQC_k/edit#gid=0)\n",
    "\n",
    "## Description\n",
    "\n",
    "In this assignment, you will have an opportunity to apply some data mining techniques that you learned in the class to a problem.\n",
    "\n",
    "To get started on this assignment, you need to download the given dataset and read the description carefully written on this page. Please note that all implementation of your program should be done with Python.\n",
    "\n",
    "You are required to form a team with at most 3 students. You and your groupmates should evenly divide the project tasks yourself. All team members are going to graded with the same score.\n",
    "\n",
    "There are two parts in this assignment. Part 1 is a programming exercise that your groups are required to complete certain tasks using Python. You should complete your Part 1 in this jupyter notebook (.ipynb file) directly. Part 2 is a group presentation that you need to present your findings on the Task 5 of Part 1.\n",
    "\n",
    "## Submission\n",
    "\n",
    "| Part | Due Date | Submission by | Files to Submit |\n",
    "|---|-----|------|----|\n",
    "| Part 1 | 1/5/2019 (Wed) 23:59 | [email to TA](mailto:kevinw@ust.hk) | this `ipynb` file. |\n",
    "| Part 2 | 7/5/2019 (Thu) during lecture | Printed hardcopy | Presentation slides (4 slides per page) |\n",
    "\n",
    "## Prerequesite\n",
    "\n",
    "You are recommended to install the following packages\n",
    "\n",
    "* pandas\n",
    "* geohash\n",
    "* matplotlib\n",
    "* sklearn\n",
    "\n",
    "To install these packages, you shall type in your terminal\n",
    "\n",
    "```\n",
    "> pip install pandas\n",
    "> pip install geohash\n",
    "> pip install matplotlib\n",
    "> pip install sklearn\n",
    "```\n",
    "\n",
    "The package geohash is a little tricky to install.\n",
    "\n",
    "## About the data and the context\n",
    "\n",
    "We are working on some data related to shared bike. There are two sets of data provided: \n",
    "* Mobike (China based data) - For Part 1 Task 1 to Task 4\n",
    "* bike share (US based data) - For Part 1 Task 5 \n",
    "\n",
    "## Download Area\n",
    "\n",
    "You can [download the data here](https://home.cse.ust.hk/~kevinw/CSIT5210/data.zip)\n",
    "\n",
    "There are some API and reference codes that might be useful for your assignment. [download code here](https://home.cse.ust.hk/~kevinw/CSIT5210/code.zip)\n",
    "\n",
    "### Mobike\n",
    "\n",
    "The data acquired from Mobike looks like the following. Apparently `orderid` is an unique ID refers to the transaction ID, `userid` refers to the registered user and `bikeid` refers to the ID of the bike. `biketype` refers to the type of the bike can be either 1 or 2. `starttime` refers to the starts of the loan. The starting location and ending location are GPS coordinates compressed in geohashed. We will let you know how to convert that back to x,y coordinates later.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>userid</th>\n",
       "      <th>bikeid</th>\n",
       "      <th>biketype</th>\n",
       "      <th>starttime</th>\n",
       "      <th>geohashed_start_loc</th>\n",
       "      <th>geohashed_end_loc</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>orderid</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1893973</th>\n",
       "      <td>451147</td>\n",
       "      <td>210617</td>\n",
       "      <td>2</td>\n",
       "      <td>2017-05-14 22:16:50</td>\n",
       "      <td>wx4snhx</td>\n",
       "      <td>wx4snhj</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4657992</th>\n",
       "      <td>1061133</td>\n",
       "      <td>465394</td>\n",
       "      <td>1</td>\n",
       "      <td>2017-05-14 22:16:52</td>\n",
       "      <td>wx4dr59</td>\n",
       "      <td>wx4dquz</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2965085</th>\n",
       "      <td>549189</td>\n",
       "      <td>310572</td>\n",
       "      <td>1</td>\n",
       "      <td>2017-05-14 22:16:51</td>\n",
       "      <td>wx4fgur</td>\n",
       "      <td>wx4fu5n</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4548579</th>\n",
       "      <td>489720</td>\n",
       "      <td>456688</td>\n",
       "      <td>1</td>\n",
       "      <td>2017-05-14 22:16:51</td>\n",
       "      <td>wx4d5r5</td>\n",
       "      <td>wx4d5r4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3936364</th>\n",
       "      <td>467449</td>\n",
       "      <td>403224</td>\n",
       "      <td>1</td>\n",
       "      <td>2017-05-14 22:16:50</td>\n",
       "      <td>wx4g27p</td>\n",
       "      <td>wx4g266</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5163705</th>\n",
       "      <td>917620</td>\n",
       "      <td>509044</td>\n",
       "      <td>1</td>\n",
       "      <td>2017-05-14 22:16:53</td>\n",
       "      <td>wx4gd2e</td>\n",
       "      <td>wx4g6pw</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19818</th>\n",
       "      <td>583391</td>\n",
       "      <td>3190</td>\n",
       "      <td>1</td>\n",
       "      <td>2017-05-14 22:16:54</td>\n",
       "      <td>wx4fhkk</td>\n",
       "      <td>wx4fh7q</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>495333</th>\n",
       "      <td>185893</td>\n",
       "      <td>67441</td>\n",
       "      <td>1</td>\n",
       "      <td>2017-05-14 22:16:53</td>\n",
       "      <td>wx4emgw</td>\n",
       "      <td>wx4emgk</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2803108</th>\n",
       "      <td>15906</td>\n",
       "      <td>295614</td>\n",
       "      <td>2</td>\n",
       "      <td>2017-05-14 22:16:55</td>\n",
       "      <td>wx4f8t9</td>\n",
       "      <td>wx4f8tj</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>271970</th>\n",
       "      <td>183740</td>\n",
       "      <td>38335</td>\n",
       "      <td>1</td>\n",
       "      <td>2017-05-14 22:16:54</td>\n",
       "      <td>wx4dzjf</td>\n",
       "      <td>wx4dzhn</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          userid  bikeid  biketype            starttime geohashed_start_loc  \\\n",
       "orderid                                                                       \n",
       "1893973   451147  210617         2  2017-05-14 22:16:50             wx4snhx   \n",
       "4657992  1061133  465394         1  2017-05-14 22:16:52             wx4dr59   \n",
       "2965085   549189  310572         1  2017-05-14 22:16:51             wx4fgur   \n",
       "4548579   489720  456688         1  2017-05-14 22:16:51             wx4d5r5   \n",
       "3936364   467449  403224         1  2017-05-14 22:16:50             wx4g27p   \n",
       "5163705   917620  509044         1  2017-05-14 22:16:53             wx4gd2e   \n",
       "19818     583391    3190         1  2017-05-14 22:16:54             wx4fhkk   \n",
       "495333    185893   67441         1  2017-05-14 22:16:53             wx4emgw   \n",
       "2803108    15906  295614         2  2017-05-14 22:16:55             wx4f8t9   \n",
       "271970    183740   38335         1  2017-05-14 22:16:54             wx4dzjf   \n",
       "\n",
       "        geohashed_end_loc  \n",
       "orderid                    \n",
       "1893973           wx4snhj  \n",
       "4657992           wx4dquz  \n",
       "2965085           wx4fu5n  \n",
       "4548579           wx4d5r4  \n",
       "3936364           wx4g266  \n",
       "5163705           wx4g6pw  \n",
       "19818             wx4fh7q  \n",
       "495333            wx4emgk  \n",
       "2803108           wx4f8tj  \n",
       "271970            wx4dzhn  "
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "mobikedata = pd.read_csv('mobikeData.csv', sep=',', nrows= 10, index_col= ['orderid'])\n",
    "mobikedata.head(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### bikeshare\n",
    "\n",
    "The data acquired from bikeshare looks like the following. `trip_id` refers to the unique ID of a transaction. Bike rented in this system has fixed parking stations and `from_station_id` and `to_station_id` are simply referring the starting and ending location of the loan. \n",
    "\n",
    "There are two types of customers: **Customer** and **Subscriber**. A **Subscriber** will register with the company with more details while a **Customer** is an ad-hoc customer that does not register."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>start_time</th>\n",
       "      <th>end_time</th>\n",
       "      <th>bikeid</th>\n",
       "      <th>tripduration</th>\n",
       "      <th>from_station_id</th>\n",
       "      <th>from_station_name</th>\n",
       "      <th>to_station_id</th>\n",
       "      <th>to_station_name</th>\n",
       "      <th>usertype</th>\n",
       "      <th>gender</th>\n",
       "      <th>birthyear</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>trip_id</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>19244622</th>\n",
       "      <td>2018-07-01 00:00:03</td>\n",
       "      <td>2018-07-01 23:56:11</td>\n",
       "      <td>5429</td>\n",
       "      <td>86,168.0</td>\n",
       "      <td>140</td>\n",
       "      <td>Dearborn Pkwy &amp; Delaware Pl</td>\n",
       "      <td>106</td>\n",
       "      <td>State St &amp; Pearson St</td>\n",
       "      <td>Customer</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19244623</th>\n",
       "      <td>2018-07-01 00:00:13</td>\n",
       "      <td>2018-07-01 00:06:39</td>\n",
       "      <td>93</td>\n",
       "      <td>386.0</td>\n",
       "      <td>153</td>\n",
       "      <td>Southport Ave &amp; Wellington Ave</td>\n",
       "      <td>250</td>\n",
       "      <td>Ashland Ave &amp; Wellington Ave</td>\n",
       "      <td>Subscriber</td>\n",
       "      <td>Male</td>\n",
       "      <td>1986.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19244624</th>\n",
       "      <td>2018-07-01 00:00:15</td>\n",
       "      <td>2018-07-01 00:23:26</td>\n",
       "      <td>2461</td>\n",
       "      <td>1,391.0</td>\n",
       "      <td>76</td>\n",
       "      <td>Lake Shore Dr &amp; Monroe St</td>\n",
       "      <td>301</td>\n",
       "      <td>Clark St &amp; Schiller St</td>\n",
       "      <td>Subscriber</td>\n",
       "      <td>Female</td>\n",
       "      <td>1987.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19244625</th>\n",
       "      <td>2018-07-01 00:00:25</td>\n",
       "      <td>2018-07-01 00:23:31</td>\n",
       "      <td>2991</td>\n",
       "      <td>1,386.0</td>\n",
       "      <td>76</td>\n",
       "      <td>Lake Shore Dr &amp; Monroe St</td>\n",
       "      <td>301</td>\n",
       "      <td>Clark St &amp; Schiller St</td>\n",
       "      <td>Subscriber</td>\n",
       "      <td>Male</td>\n",
       "      <td>1986.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19244626</th>\n",
       "      <td>2018-07-01 00:00:27</td>\n",
       "      <td>2018-07-01 00:11:23</td>\n",
       "      <td>2851</td>\n",
       "      <td>656.0</td>\n",
       "      <td>60</td>\n",
       "      <td>Dayton St &amp; North Ave</td>\n",
       "      <td>166</td>\n",
       "      <td>Ashland Ave &amp; Wrightwood Ave</td>\n",
       "      <td>Subscriber</td>\n",
       "      <td>Male</td>\n",
       "      <td>1961.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19244627</th>\n",
       "      <td>2018-07-01 00:00:35</td>\n",
       "      <td>2018-07-01 00:16:09</td>\n",
       "      <td>5980</td>\n",
       "      <td>934.0</td>\n",
       "      <td>128</td>\n",
       "      <td>Damen Ave &amp; Chicago Ave</td>\n",
       "      <td>71</td>\n",
       "      <td>Morgan St &amp; Lake St</td>\n",
       "      <td>Subscriber</td>\n",
       "      <td>Male</td>\n",
       "      <td>1995.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19244628</th>\n",
       "      <td>2018-07-01 00:00:37</td>\n",
       "      <td>2018-07-01 00:10:14</td>\n",
       "      <td>3132</td>\n",
       "      <td>577.0</td>\n",
       "      <td>168</td>\n",
       "      <td>Michigan Ave &amp; 14th St</td>\n",
       "      <td>321</td>\n",
       "      <td>Wabash Ave &amp; 9th St</td>\n",
       "      <td>Customer</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19244629</th>\n",
       "      <td>2018-07-01 00:00:55</td>\n",
       "      <td>2018-07-01 00:09:20</td>\n",
       "      <td>2281</td>\n",
       "      <td>505.0</td>\n",
       "      <td>168</td>\n",
       "      <td>Michigan Ave &amp; 14th St</td>\n",
       "      <td>321</td>\n",
       "      <td>Wabash Ave &amp; 9th St</td>\n",
       "      <td>Customer</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19244630</th>\n",
       "      <td>2018-07-01 00:01:38</td>\n",
       "      <td>2018-07-01 00:25:25</td>\n",
       "      <td>3465</td>\n",
       "      <td>1,427.0</td>\n",
       "      <td>229</td>\n",
       "      <td>Southport Ave &amp; Roscoe St</td>\n",
       "      <td>324</td>\n",
       "      <td>Stockton Dr &amp; Wrightwood Ave</td>\n",
       "      <td>Customer</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19244631</th>\n",
       "      <td>2018-07-01 00:01:44</td>\n",
       "      <td>2018-07-01 00:25:25</td>\n",
       "      <td>3873</td>\n",
       "      <td>1,421.0</td>\n",
       "      <td>229</td>\n",
       "      <td>Southport Ave &amp; Roscoe St</td>\n",
       "      <td>324</td>\n",
       "      <td>Stockton Dr &amp; Wrightwood Ave</td>\n",
       "      <td>Customer</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                   start_time             end_time  bikeid tripduration  \\\n",
       "trip_id                                                                   \n",
       "19244622  2018-07-01 00:00:03  2018-07-01 23:56:11    5429     86,168.0   \n",
       "19244623  2018-07-01 00:00:13  2018-07-01 00:06:39      93        386.0   \n",
       "19244624  2018-07-01 00:00:15  2018-07-01 00:23:26    2461      1,391.0   \n",
       "19244625  2018-07-01 00:00:25  2018-07-01 00:23:31    2991      1,386.0   \n",
       "19244626  2018-07-01 00:00:27  2018-07-01 00:11:23    2851        656.0   \n",
       "19244627  2018-07-01 00:00:35  2018-07-01 00:16:09    5980        934.0   \n",
       "19244628  2018-07-01 00:00:37  2018-07-01 00:10:14    3132        577.0   \n",
       "19244629  2018-07-01 00:00:55  2018-07-01 00:09:20    2281        505.0   \n",
       "19244630  2018-07-01 00:01:38  2018-07-01 00:25:25    3465      1,427.0   \n",
       "19244631  2018-07-01 00:01:44  2018-07-01 00:25:25    3873      1,421.0   \n",
       "\n",
       "          from_station_id               from_station_name  to_station_id  \\\n",
       "trip_id                                                                    \n",
       "19244622              140     Dearborn Pkwy & Delaware Pl            106   \n",
       "19244623              153  Southport Ave & Wellington Ave            250   \n",
       "19244624               76       Lake Shore Dr & Monroe St            301   \n",
       "19244625               76       Lake Shore Dr & Monroe St            301   \n",
       "19244626               60           Dayton St & North Ave            166   \n",
       "19244627              128         Damen Ave & Chicago Ave             71   \n",
       "19244628              168          Michigan Ave & 14th St            321   \n",
       "19244629              168          Michigan Ave & 14th St            321   \n",
       "19244630              229       Southport Ave & Roscoe St            324   \n",
       "19244631              229       Southport Ave & Roscoe St            324   \n",
       "\n",
       "                       to_station_name    usertype  gender  birthyear  \n",
       "trip_id                                                                \n",
       "19244622         State St & Pearson St    Customer     NaN        NaN  \n",
       "19244623  Ashland Ave & Wellington Ave  Subscriber    Male     1986.0  \n",
       "19244624        Clark St & Schiller St  Subscriber  Female     1987.0  \n",
       "19244625        Clark St & Schiller St  Subscriber    Male     1986.0  \n",
       "19244626  Ashland Ave & Wrightwood Ave  Subscriber    Male     1961.0  \n",
       "19244627           Morgan St & Lake St  Subscriber    Male     1995.0  \n",
       "19244628           Wabash Ave & 9th St    Customer     NaN        NaN  \n",
       "19244629           Wabash Ave & 9th St    Customer     NaN        NaN  \n",
       "19244630  Stockton Dr & Wrightwood Ave    Customer     NaN        NaN  \n",
       "19244631  Stockton Dr & Wrightwood Ave    Customer     NaN        NaN  "
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "divvybike = pd.read_csv('bikeshareTraining.csv', sep=',', nrows = 10, index_col=['trip_id'])\n",
    "divvybike.head(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Part 1 - Programming Task\n",
    "\n",
    "Your team are required to complete the following tasks on this Jupyter notebook. \n",
    "\n",
    "1. Data Preprocessing & Statistics - with Mobike Data\n",
    "2. Data Clustering - with Mobike Data\n",
    "3. Simple Data Visualization - with Mobike Data\n",
    "4. Frequent Pattern Mining - with Mobike Data\n",
    "5. Prediction - with bikeshare Data\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Task 1 - Data Preprocessing and Statistics\n",
    "#\n",
    "#\n",
    "# Task 1.1 Read Mobike Data in using the API Pandas.read_csv so that the column 'starttime' is read as datetime64.\n",
    "#                 Hint: use the parameter parse_dates\n",
    "#                  ref: https://pandas.pydata.org/pandas-docs/stable/reference/api/pandas.read_csv.html\n",
    "#                 To make sure your code works you might want to read only the first 1000 rows and expand it later\n",
    "\n",
    "\n",
    "\n",
    "# Task 1.2 Convert the field geohashed_start_loc and geohashed_end_loc into x-y coordinate using the API Geohash.decode\n",
    "#                  The package Geohash can be found from pip. You might encounter the problem \n",
    "#                   'python3.5.2 can't find the module '  ref: https://github.com/vinsci/geohash/issues/4\n",
    "#                    This can be fixed very easily. Or\n",
    "#                   You might directly use the fixed version of Geohash in our project package.\n",
    "\n",
    "\n",
    "# Task 1.3 Create the column 'distance' based on the Euclidean distance  that the order has traveled.\n",
    "\n",
    "\n",
    "#  Task 1.4.1  Check the memory you have spent by the API .info()\n",
    "\n",
    "#  Task 1.4.2  Compress the field userid bikeid using a smaller data type int32 / uint32 and the field biketype using int8\n",
    "\n",
    "# Task 1.343 Check the memory you have spent again\n",
    "\n",
    "# Task 1.4.4 Fetch the first 10 lines of your data to preview it.\n",
    "\n",
    "\n",
    "# Task 1.5  Display the count, mean, standard derviation of the int type variable and \n",
    "#                  display the earliest and latest starttime.\n",
    "\n",
    "# Task 1.6 Find the number of order between (8am to 9am)   and the order between (1am to 2am)\n",
    "#                 Note: Instead of using only the first 1000 rows, expand your selection of rows to collect enough data.\n",
    "#                Hint: try the API between_time of DataFrame. \n",
    "#           ref:  https://pandas.pydata.org/pandas-docs/stable/reference/api/pandas.DataFrame.between_time.html#pandas.DataFrame.between_time\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Task 2 - Data Clustering \n",
    "#\n",
    "#\n",
    "# Task 2.1 Create a DataFrame that contains two columns. \n",
    "#                 The first column (the index) is a time series 0:00, 0:15, 0:30, 0:45, 1:00,... 23:00, 23:15, 23:30, 23:45\n",
    "#                  The second column is an integer that counts the number of order between in the interval. For example, 0:00 should contains all order happens on or after 0:00 to 0:15.\n",
    "#  This task is less straight forward, at least in our solution. So let's break down a little bit.\n",
    "#  Task 2.1.1 Create a list of string containing the series '0:00', '0:15', '0:30', ... '23:45' \n",
    "#                     Hint: A double loop with if-else can do the job.\n",
    "\n",
    "\n",
    "# Task 2.1.2 Count the number of orders. You might use between_time again.\n",
    "\n",
    "\n",
    "# Task 2.2.1  Use K-mean algorithm to find 300 cluster centers of the coordinates obtained from  Task 1.2\n",
    "#                  You may implement your own K-mean algorithm or simply adopt the API sklearn.cluster.KMeans\n",
    "#                   ref: https://scikit-learn.org/stable/modules/generated/sklearn.cluster.KMeans.html\n",
    "                   \n",
    "\n",
    "\n",
    "    \n",
    "# Task 2.2.2 Describe how many % of order has started from a cluster centers and ends at the same cluster centers.  \n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Task 3 - Simple Data Visualization \n",
    "#\n",
    "#\n",
    "# Task 3.1 Using data obtained from Task 1.6. Plot a curveof the volume of order in different times of a day.\n",
    "#                    Hint: try the API DataFrame.plot\n",
    "\n",
    "\n",
    "# Task 3.2 Using data obtained from Task 2.2.1. Plot a histogram of the volume of order in different cluster centers\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Task 4 - Frequent Pattern Mining \n",
    "#\n",
    "#\n",
    "# Task 4.1 Apply FPGrowth algorithm, either using existing API or write your own, to identify which set of users are likely to go-together. \n",
    "#                 Definition of go-together: they starts at the same cluster centers and their start time is in the same 15-minutes timeslot.\n",
    " #                This task may not be straight forward as you may need to build the list of transaction first."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Task 5 - Prediction - use bikeshare data\n",
    "\n",
    "You are given a set of training data and 1000 rows of testing data obtained from the same city. The testing data will be 1 days to 7 days after the end of the training data. The fields `to_station_name` and `to_station_id` will be masked with the number -1 in the testing data. Your job is to predict the field `to_station_id`. \n",
    "\n",
    "Write a function that takes two input filenames (the training data and the testing data csv) and output a DataFrame that predict the `to_station_id`. Please note that:\n",
    "* Your function may only predict 1 value for `to_station_id`; \n",
    "* The accurarcy function is defined as `total_numbers_of_match` / `total_number_of_prediction`. \n",
    "* An empty prediction would be counted as one wrong prediction.\n",
    "* You are allowed to use any external data (e.g. weather, map, etc..) for your prediciton. However, this set of data are taken from bikeshare and you are not allowed to lookup the data from the internet.\n",
    "* **A higher accuracy does not immediate imply a higher mark for the project. We value more on how you choose your algorithm and how you fine tune your parameters.**\n",
    "\n",
    "\n",
    "\n",
    "We provide you a reference code (`knn3.py`) written by some Chinese programmer/data scientist that work on the Mobike data. \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Task 5 Code goes here"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Part 2 - Group Presentation\n",
    "\n",
    "Prepare a 5 minutes presentation on your Task 5 prediction work. You will be given another set of training set, testing set of you Task 5 **on 2/5/2019**. Compute the accuracy yourself and include it in your presentation. Your presentation should be focus on why would your choose that particular algorithm and what optimization/fine tuning you have done to improve the accuracy. You can also comment on your accuracy and suggest how could that be improved. \n",
    "\n",
    "You may use the following line to measure the accurarcy\n",
    "```\n",
    "groundtruth['predict'] = output['to_station_id']\n",
    "groundtruth[ groundtruth['predict'] == groundtruth['to_station_id']].count()\n",
    "```\n",
    "\n",
    "Since this is a short presentation, you may assign any member to present the work.\n",
    "\n",
    "**Note: Again, a higher accuracy does not immediate imply a higher mark.**"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
